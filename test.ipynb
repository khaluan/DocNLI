{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "\n",
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                if sys.version_info[0] == 2:\n",
    "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "\n",
    "class RteProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the RTE data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_MNLI_train_and_dev(self, train_filename, dev_filename_list):\n",
    "        '''\n",
    "        classes: [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        '''\n",
    "        examples_per_file = []\n",
    "        for filename in [train_filename]+dev_filename_list:\n",
    "            examples=[]\n",
    "            readfile = codecs.open(filename, 'r', 'utf-8')\n",
    "            line_co=0\n",
    "            for row in readfile:\n",
    "                if line_co>0:\n",
    "                    line=row.strip().split('\\t')\n",
    "                    guid = \"train-\"+str(line_co-1)\n",
    "                    # text_a = 'MNLI. '+line[8].strip()\n",
    "                    text_a = line[8].strip()\n",
    "                    text_b = line[9].strip()\n",
    "                    label = line[-1].strip() #[\"entailment\", \"neutral\", \"contradiction\"]\n",
    "                    examples.append(\n",
    "                        InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "                line_co+=1\n",
    "            readfile.close()\n",
    "            print('loaded  MNLI size:', len(examples))\n",
    "            examples_per_file.append(examples)\n",
    "        dev_examples = []\n",
    "        for listt in examples_per_file[1:]:\n",
    "            dev_examples+=listt\n",
    "        return examples_per_file[0], dev_examples #train, dev\n",
    "\n",
    "    def get_labels(self):\n",
    "        'here we keep the three-way in MNLI training '\n",
    "        return [\"entailment\", \"not_entailment\"]\n",
    "        # return [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1]\n",
    "            text_b = line[2]\n",
    "            label = line[-1]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "\n",
    "# def convert_examples_to_features(examples, label_list, max_seq_length,\n",
    "#                                  tokenizer, output_mode,\n",
    "#                                  cls_token_at_end=False,\n",
    "#                                  cls_token='[CLS]',\n",
    "#                                  cls_token_segment_id=1,\n",
    "#                                  sep_token='[SEP]',\n",
    "#                                  sep_token_extra=False,\n",
    "#                                  pad_on_left=False,\n",
    "#                                  pad_token=0,\n",
    "#                                  pad_token_segment_id=0,\n",
    "#                                  sequence_a_segment_id=0,\n",
    "#                                  sequence_b_segment_id=1,\n",
    "#                                  mask_padding_with_zero=True):\n",
    "#     \"\"\" Loads a data file into a list of `InputBatch`s\n",
    "#         `cls_token_at_end` define the location of the CLS token:\n",
    "#             - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "#             - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "#         `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "#     \"\"\"\n",
    "\n",
    "#     label_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "#     features = []\n",
    "#     for (ex_index, example) in enumerate(examples):\n",
    "#         if ex_index % 10000 == 0:\n",
    "#             logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "#         tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "#         tokens_b = None\n",
    "#         if example.text_b:\n",
    "#             tokens_b = tokenizer.tokenize(example.text_b)\n",
    "#             # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "#             # length is less than the specified length.\n",
    "#             # Account for [CLS], [SEP], [SEP] with \"- 3\". \" -4\" for RoBERTa.\n",
    "#             special_tokens_count = 4 if sep_token_extra else 3\n",
    "#             _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - special_tokens_count)\n",
    "#         else:\n",
    "#             # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "#             special_tokens_count = 3 if sep_token_extra else 2\n",
    "#             if len(tokens_a) > max_seq_length - special_tokens_count:\n",
    "#                 tokens_a = tokens_a[:(max_seq_length - special_tokens_count)]\n",
    "\n",
    "#         # The convention in BERT is:\n",
    "#         # (a) For sequence pairs:\n",
    "#         #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "#         #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "#         # (b) For single sequences:\n",
    "#         #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "#         #  type_ids:   0   0   0   0  0     0   0\n",
    "#         #\n",
    "#         # Where \"type_ids\" are used to indicate whether this is the first\n",
    "#         # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "#         # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "#         # embedding vector (and position vector). This is not *strictly* necessary\n",
    "#         # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "#         # it easier for the model to learn the concept of sequences.\n",
    "#         #\n",
    "#         # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "#         # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "#         # the entire model is fine-tuned.\n",
    "#         tokens = tokens_a + [sep_token]\n",
    "#         if sep_token_extra:\n",
    "#             # roberta uses an extra separator b/w pairs of sentences\n",
    "#             tokens += [sep_token]\n",
    "#         segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "#         if tokens_b:\n",
    "#             tokens += tokens_b + [sep_token]\n",
    "#             segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
    "\n",
    "#         if cls_token_at_end:\n",
    "#             tokens = tokens + [cls_token]\n",
    "#             segment_ids = segment_ids + [cls_token_segment_id]\n",
    "#         else:\n",
    "#             tokens = [cls_token] + tokens\n",
    "#             segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "#         input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "#         # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "#         # tokens are attended to.\n",
    "#         input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "#         # Zero-pad up to the sequence length.\n",
    "#         padding_length = max_seq_length - len(input_ids)\n",
    "#         if pad_on_left:\n",
    "#             input_ids = ([pad_token] * padding_length) + input_ids\n",
    "#             input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "#             segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "#         else:\n",
    "#             input_ids = input_ids + ([pad_token] * padding_length)\n",
    "#             input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "#             segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "#         assert len(input_ids) == max_seq_length\n",
    "#         assert len(input_mask) == max_seq_length\n",
    "#         assert len(segment_ids) == max_seq_length\n",
    "\n",
    "#         if output_mode == \"classification\":\n",
    "#             label_id = label_map[example.label]\n",
    "#         elif output_mode == \"regression\":\n",
    "#             label_id = float(example.label)\n",
    "#         else:\n",
    "#             raise KeyError(output_mode)\n",
    "\n",
    "#         # if ex_index < 5:\n",
    "#         #     logger.info(\"*** Example ***\")\n",
    "#         #     logger.info(\"guid: %s\" % (example.guid))\n",
    "#         #     logger.info(\"tokens: %s\" % \" \".join(\n",
    "#         #             [str(x) for x in tokens]))\n",
    "#         #     logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "#         #     logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "#         #     logger.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "#         #     logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "#         features.append(\n",
    "#                 InputFeatures(input_ids=input_ids,\n",
    "#                               input_mask=input_mask,\n",
    "#                               segment_ids=segment_ids,\n",
    "#                               label_id=label_id))\n",
    "#     return features\n",
    "\n",
    "# def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "#     \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "#     # This is a simple heuristic which will always truncate the longer sequence\n",
    "#     # one token at a time. This makes more sense than truncating an equal percent\n",
    "#     # of tokens from each, since if one sequence is very short then each token\n",
    "#     # that's truncated likely contains more information than a longer sequence.\n",
    "#     while True:\n",
    "#         total_length = len(tokens_a) + len(tokens_b)\n",
    "#         if total_length <= max_length:\n",
    "#             break\n",
    "#         if len(tokens_a) > len(tokens_b):\n",
    "#             tokens_a.pop()\n",
    "#         else:\n",
    "#             tokens_b.pop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # parser = argparse.ArgumentParser()\n",
    "\n",
    "    # ## Required parameters\n",
    "    # parser.add_argument(\"--task_name\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The name of the task to train.\")\n",
    "    # ## Other parameters\n",
    "    # parser.add_argument(\"--cache_dir\",\n",
    "    #                     default=\"\",\n",
    "    #                     type=str,\n",
    "    #                     help=\"Where do you want to store the pre-trained models downloaded from s3\")\n",
    "\n",
    "    # parser.add_argument(\"--data_label\",\n",
    "    #                     default=\"\",\n",
    "    #                     type=str,\n",
    "    #                     help=\"Where do you want to store the pre-trained models downloaded from s3\")\n",
    "\n",
    "    # parser.add_argument(\"--max_seq_length\",\n",
    "    #                     default=128,\n",
    "    #                     type=int,\n",
    "    #                     help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
    "    #                          \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
    "    #                          \"than this will be padded.\")\n",
    "    # parser.add_argument(\"--do_train\",\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run training.\")\n",
    "    # parser.add_argument(\"--do_eval\",\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run eval on the dev set.\")\n",
    "    # parser.add_argument(\"--do_lower_case\",\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Set this flag if you are using an uncased model.\")\n",
    "    # parser.add_argument(\"--train_batch_size\",\n",
    "    #                     default=16,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for training.\")\n",
    "    # parser.add_argument(\"--eval_batch_size\",\n",
    "    #                     default=64,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for eval.\")\n",
    "    # parser.add_argument(\"--learning_rate\",\n",
    "    #                     default=1e-5,\n",
    "    #                     type=float,\n",
    "    #                     help=\"The initial learning rate for Adam.\")\n",
    "    # parser.add_argument(\"--num_train_epochs\",\n",
    "    #                     default=3.0,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Total number of training epochs to perform.\")\n",
    "    # parser.add_argument(\"--warmup_proportion\",\n",
    "    #                     default=0.1,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    #                          \"E.g., 0.1 = 10%% of training.\")\n",
    "    # parser.add_argument(\"--no_cuda\",\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether not to use CUDA when available\")\n",
    "    # parser.add_argument(\"--local_rank\",\n",
    "    #                     type=int,\n",
    "    #                     default=-1,\n",
    "    #                     help=\"local_rank for distributed training on gpus\")\n",
    "    # parser.add_argument('--seed',\n",
    "    #                     type=int,\n",
    "    #                     default=42,\n",
    "    #                     help=\"random seed for initialization\")\n",
    "    # parser.add_argument('--gradient_accumulation_steps',\n",
    "    #                     type=int,\n",
    "    #                     default=1,\n",
    "    #                     help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    # parser.add_argument('--fp16',\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to use 16-bit float precision instead of 32-bit\")\n",
    "    # parser.add_argument('--loss_scale',\n",
    "    #                     type=float, default=0,\n",
    "    #                     help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n",
    "    #                          \"0 (default value): dynamic loss scaling.\\n\"\n",
    "    #                          \"Positive power of 2: static loss scaling value.\\n\")\n",
    "    # parser.add_argument('--server_ip', type=str, default='', help=\"Can be used for distant debugging.\")\n",
    "    # parser.add_argument('--server_port', type=str, default='', help=\"Can be used for distant debugging.\")\n",
    "\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "\n",
    "    # processors = {\n",
    "    #     \"rte\": RteProcessor\n",
    "    # }\n",
    "\n",
    "    # output_modes = {\n",
    "    #     \"rte\": \"classification\"\n",
    "    # }\n",
    "\n",
    "    # if args.local_rank == -1 or args.no_cuda:\n",
    "    #     device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    #     n_gpu = torch.cuda.device_count()\n",
    "    # else:\n",
    "    #     torch.cuda.set_device(args.local_rank)\n",
    "    #     device = torch.device(\"cuda\", args.local_rank)\n",
    "    #     n_gpu = 1\n",
    "    #     # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    #     torch.distributed.init_process_group(backend='nccl')\n",
    "    # logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "    #     device, n_gpu, bool(args.local_rank != -1), args.fp16))\n",
    "\n",
    "    if args.gradient_accumulation_steps < 1:\n",
    "        raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "                            args.gradient_accumulation_steps))\n",
    "\n",
    "    args.train_batch_size = args.train_batch_size // args.gradient_accumulation_steps\n",
    "\n",
    "    # random.seed(args.seed)\n",
    "    # np.random.seed(args.seed)\n",
    "    # torch.manual_seed(args.seed)\n",
    "    # if n_gpu > 0:\n",
    "    #     torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    # if not args.do_train and not args.do_eval:\n",
    "    #     raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "\n",
    "    task_name = args.task_name.lower()\n",
    "\n",
    "    if task_name not in processors:\n",
    "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "\n",
    "\n",
    "\n",
    "    processor = processors[task_name]()\n",
    "    output_mode = output_modes[task_name]\n",
    "\n",
    "    # test_examples = load_DocNLI('test', hypo_only=False)\n",
    "\n",
    "    # label_list = [\"entailment\", \"not_entailment\"]#, \"contradiction\"]\n",
    "    # num_labels = len(label_list)\n",
    "    # print('num_labels:', num_labels,  ' test size:', len(test_examples))\n",
    "\n",
    "    # device = torch.device('cpu')\n",
    "    # model = RobertaForSequenceClassification(num_labels)\n",
    "    # tokenizer = RobertaTokenizer.from_pretrained(pretrain_model_dir, do_lower_case=args.do_lower_case)\n",
    "    # model.load_state_dict(torch.load('DocNLI.pretrained.RoBERTA.model.pt', map_location=device))\n",
    "\n",
    "    # model.to(device)\n",
    "\n",
    "\n",
    "    '''load test set'''\n",
    "    \n",
    "\n",
    "\n",
    "    '''\n",
    "    start evaluate on dev set after this epoch\n",
    "    '''\n",
    "    model.eval()\n",
    "    final_test_performance = evaluation(test_dataloader, device, model)\n",
    "    print('final_test_performance:', final_test_performance)\n",
    "\n",
    "def evaluation(dev_dataloader, device, model):\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "    gold_label_ids = []\n",
    "    # print('Evaluating...')\n",
    "    for input_ids, input_mask, segment_ids, label_ids in dev_dataloader:\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        gold_label_ids+=list(label_ids.detach().cpu().numpy())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, input_mask)\n",
    "        if len(preds) == 0:\n",
    "            preds.append(logits.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds[0] = np.append(preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        nb_eval_steps+=1\n",
    "        print('eval_steps:', nb_eval_steps, '/', len(dev_dataloader))\n",
    "\n",
    "    preds = preds[0]\n",
    "\n",
    "    pred_probs = softmax(preds,axis=1)\n",
    "    pred_label_ids = list(np.argmax(pred_probs, axis=1))\n",
    "\n",
    "    gold_label_ids = gold_label_ids\n",
    "    assert len(pred_label_ids) == len(gold_label_ids)\n",
    "    # print('gold_label_ids:', gold_label_ids)\n",
    "    # print('pred_label_ids:', pred_label_ids)\n",
    "    f1 = f1_score(gold_label_ids, pred_label_ids, pos_label= 0, average='binary')\n",
    "    return f1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_DIR = '/root/Dataset/COSMOS/cosmos_anns_acm/acm_anns/'\n",
    "CONTEXT_DIR = '/root/Dataset/COSMOS/context/Context_EL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaModel\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from scipy.special import softmax\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "from itertools import groupby\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code snippet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None, image_id = None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "        self.image_id = image_id\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Text_a: {self.text_a}, text_b: {self.text_b}, image_id: {self.image_id}'\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "\n",
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                if sys.version_info[0] == 2:\n",
    "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "\n",
    "class RteProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the RTE data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_MNLI_train_and_dev(self, train_filename, dev_filename_list):\n",
    "        '''\n",
    "        classes: [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        '''\n",
    "        examples_per_file = []\n",
    "        for filename in [train_filename]+dev_filename_list:\n",
    "            examples=[]\n",
    "            readfile = codecs.open(filename, 'r', 'utf-8')\n",
    "            line_co=0\n",
    "            for row in readfile:\n",
    "                if line_co>0:\n",
    "                    line=row.strip().split('\\t')\n",
    "                    guid = \"train-\"+str(line_co-1)\n",
    "                    # text_a = 'MNLI. '+line[8].strip()\n",
    "                    text_a = line[8].strip()\n",
    "                    text_b = line[9].strip()\n",
    "                    label = line[-1].strip() #[\"entailment\", \"neutral\", \"contradiction\"]\n",
    "                    examples.append(\n",
    "                        InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "                line_co+=1\n",
    "            readfile.close()\n",
    "            print('loaded  MNLI size:', len(examples))\n",
    "            examples_per_file.append(examples)\n",
    "        dev_examples = []\n",
    "        for listt in examples_per_file[1:]:\n",
    "            dev_examples+=listt\n",
    "        return examples_per_file[0], dev_examples #train, dev\n",
    "\n",
    "    def get_labels(self):\n",
    "        'here we keep the three-way in MNLI training '\n",
    "        return [\"entailment\", \"not_entailment\"]\n",
    "        # return [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1]\n",
    "            text_b = line[2]\n",
    "            label = line[-1]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_id(filename: str) -> int:\n",
    "    return int(re.search('([0-9]+)_[0-9]+\\.txt', filename).group(1))\n",
    "\n",
    "context_files = [join(CONTEXT_DIR, file) for file in listdir(CONTEXT_DIR) if isfile(join(CONTEXT_DIR, file))]\n",
    "context_files = sorted(context_files, key=get_image_id)\n",
    "\n",
    "context_files_grouped_by_image_id = {key: list(val) for key, val in groupby(context_files, key = get_image_id)}\n",
    "\n",
    "def load_DocNLI(hypo_only=False):\n",
    "    data = pd.read_json(join(ANNOTATION_DIR, 'test_data.json'), lines=True)\n",
    "    examples = []\n",
    "    for i, dic in data.iterrows():\n",
    "        for filename in context_files_grouped_by_image_id.get(i, []):\n",
    "            with open(filename, 'r', encoding='utf8') as file:\n",
    "                content = json.load(file)\n",
    "                context = content['context']\n",
    "                hypothesis1 = data.iloc[i].caption1\n",
    "                hypothesis2 = data.iloc[i].caption2\n",
    "                label = 0\n",
    "                examples.append(InputExample(guid='ex', text_a=context, text_b=hypothesis1, label='entailment', image_id = i))\n",
    "                examples.append(InputExample(guid='ex', text_a=context, text_b=hypothesis2, label='not_entailment', image_id = i))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length,\n",
    "                                 tokenizer, output_mode,\n",
    "                                 cls_token_at_end=False,\n",
    "                                 cls_token='[CLS]',\n",
    "                                 cls_token_segment_id=1,\n",
    "                                 sep_token='[SEP]',\n",
    "                                 sep_token_extra=False,\n",
    "                                 pad_on_left=False,\n",
    "                                 pad_token=0,\n",
    "                                 pad_token_segment_id=0,\n",
    "                                 sequence_a_segment_id=0,\n",
    "                                 sequence_b_segment_id=1,\n",
    "                                 mask_padding_with_zero=True):\n",
    "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
    "        `cls_token_at_end` define the location of the CLS token:\n",
    "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        # if ex_index % 10000 == 0:\n",
    "        #     logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        tokens_b = None\n",
    "        if example.text_b:\n",
    "            tokens_b = tokenizer.tokenize(example.text_b)\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\". \" -4\" for RoBERTa.\n",
    "            special_tokens_count = 4 if sep_token_extra else 3\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - special_tokens_count)\n",
    "        else:\n",
    "            # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "            special_tokens_count = 3 if sep_token_extra else 2\n",
    "            if len(tokens_a) > max_seq_length - special_tokens_count:\n",
    "                tokens_a = tokens_a[:(max_seq_length - special_tokens_count)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids:   0   0   0   0  0     0   0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = tokens_a + [sep_token]\n",
    "        if sep_token_extra:\n",
    "            # roberta uses an extra separator b/w pairs of sentences\n",
    "            tokens += [sep_token]\n",
    "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens += tokens_b + [sep_token]\n",
    "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
    "\n",
    "        if cls_token_at_end:\n",
    "            tokens = tokens + [cls_token]\n",
    "            segment_ids = segment_ids + [cls_token_segment_id]\n",
    "        else:\n",
    "            tokens = [cls_token] + tokens\n",
    "            segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        if output_mode == \"classification\":\n",
    "            label_id = label_map[example.label]\n",
    "        elif output_mode == \"regression\":\n",
    "            label_id = float(example.label)\n",
    "        else:\n",
    "            raise KeyError(output_mode)\n",
    "\n",
    "        # if ex_index < 5:\n",
    "        #     logger.info(\"*** Example ***\")\n",
    "        #     logger.info(\"guid: %s\" % (example.guid))\n",
    "        #     logger.info(\"tokens: %s\" % \" \".join(\n",
    "        #             [str(x) for x in tokens]))\n",
    "        #     logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "        #     logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "        #     logger.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "        #     logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dev_dataloader, device, model):\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "    gold_label_ids = []\n",
    "    # print('Evaluating...')\n",
    "    for input_ids, input_mask, segment_ids, label_ids in dev_dataloader:\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        gold_label_ids+=list(label_ids.detach().cpu().numpy())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, input_mask)\n",
    "        if len(preds) == 0:\n",
    "            preds.append(logits.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds[0] = np.append(preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        nb_eval_steps+=1\n",
    "        print('eval_steps:', nb_eval_steps, '/', len(dev_dataloader))\n",
    "\n",
    "    preds = preds[0]\n",
    "\n",
    "    pred_probs = softmax(preds,axis=1)\n",
    "    pred_label_ids = list(np.argmax(pred_probs, axis=1))\n",
    "\n",
    "    gold_label_ids = gold_label_ids\n",
    "    assert len(pred_label_ids) == len(gold_label_ids)\n",
    "    # print('gold_label_ids:', gold_label_ids)\n",
    "    # print('pred_label_ids:', pred_label_ids)\n",
    "    # f1 = f1_score(gold_label_ids, pred_label_ids, pos_label= 0, average='binary')\n",
    "    # return f1\n",
    "    return pred_label_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, do_lower_case = True, \n",
    "                    max_seq_length = 512,\n",
    "                    seed = 42, \n",
    "                    eval_batch_size = 32) -> None: \n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.do_lower_case = do_lower_case\n",
    "        self.seed = seed\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        pass\n",
    "\n",
    "args = Args()\n",
    "\n",
    "device = torch.device('cuda', 2)\n",
    "label_list = [\"entailment\", \"not_entailment\"]#, \"contradiction\"]\n",
    "num_labels = len(label_list)\n",
    "\n",
    "processors = {\n",
    "    \"rte\": RteProcessor\n",
    "}\n",
    "\n",
    "output_modes = {\n",
    "    \"rte\": \"classification\"\n",
    "}\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "output_mode = 'classification'\n",
    "# print('num_labels:', num_labels,  ' test size:', len(test_examples))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta_single): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (single_hidden2tag): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_hidden_dim = 1024\n",
    "pretrain_model_dir = 'roberta-large'\n",
    "\n",
    "class RobertaForSequenceClassification(nn.Module):\n",
    "    def __init__(self, tagset_size):\n",
    "        super(RobertaForSequenceClassification, self).__init__()\n",
    "        self.tagset_size = tagset_size\n",
    "\n",
    "        self.roberta_single= RobertaModel.from_pretrained(pretrain_model_dir)\n",
    "        self.single_hidden2tag = RobertaClassificationHead(bert_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, input_ids, input_mask):\n",
    "        outputs_single = self.roberta_single(input_ids, input_mask, None)\n",
    "        hidden_states_single = outputs_single[1]#torch.tanh(self.hidden_layer_2(torch.tanh(self.hidden_layer_1(outputs_single[1])))) #(batch, hidden)\n",
    "\n",
    "        score_single = self.single_hidden2tag(hidden_states_single) #(batch, tag_set)\n",
    "        return score_single\n",
    "\n",
    "\n",
    "\n",
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"wenpeng overwrite it so to accept matrix as input\"\"\"\n",
    "\n",
    "    def __init__(self, bert_hidden_dim, num_labels):\n",
    "        super(RobertaClassificationHead, self).__init__()\n",
    "        self.dense = nn.Linear(bert_hidden_dim, bert_hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(bert_hidden_dim, num_labels)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = features#[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "    \n",
    "model = RobertaForSequenceClassification(num_labels)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(pretrain_model_dir, do_lower_case=args.do_lower_case)\n",
    "model.load_state_dict(torch.load('/root/ModelCache/DocNLI.pretrained.RoBERTA.model.pt', map_location=device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = load_DocNLI()\n",
    "test_features = convert_examples_to_features(\n",
    "        test_examples, label_list, args.max_seq_length, tokenizer, output_mode,\n",
    "        cls_token_at_end=False,#bool(args.model_type in ['xlnet']),            # xlnet has a cls token at the end\n",
    "        cls_token=tokenizer.cls_token,\n",
    "        cls_token_segment_id=0,#2 if args.model_type in ['xlnet'] else 0,\n",
    "        sep_token=tokenizer.sep_token,\n",
    "        sep_token_extra=True,#bool(args.model_type in ['roberta']),           # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "        pad_on_left=False,#bool(args.model_type in ['xlnet']),                 # pad on the left for xlnet\n",
    "        pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "        pad_token_segment_id=0)#4 if args.model_type in ['xlnet'] else 0,)\n",
    "\n",
    "test_all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "test_all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "test_all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "test_all_label_ids = torch.tensor([f.label_id for f in test_features], dtype=torch.long)\n",
    "\n",
    "test_data = TensorDataset(test_all_input_ids, test_all_input_mask, test_all_segment_ids, test_all_label_ids)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args.eval_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_steps: 1 / 371\n",
      "eval_steps: 2 / 371\n",
      "eval_steps: 3 / 371\n",
      "eval_steps: 4 / 371\n",
      "eval_steps: 5 / 371\n",
      "eval_steps: 6 / 371\n",
      "eval_steps: 7 / 371\n",
      "eval_steps: 8 / 371\n",
      "eval_steps: 9 / 371\n",
      "eval_steps: 10 / 371\n",
      "eval_steps: 11 / 371\n",
      "eval_steps: 12 / 371\n",
      "eval_steps: 13 / 371\n",
      "eval_steps: 14 / 371\n",
      "eval_steps: 15 / 371\n",
      "eval_steps: 16 / 371\n",
      "eval_steps: 17 / 371\n",
      "eval_steps: 18 / 371\n",
      "eval_steps: 19 / 371\n",
      "eval_steps: 20 / 371\n",
      "eval_steps: 21 / 371\n",
      "eval_steps: 22 / 371\n",
      "eval_steps: 23 / 371\n",
      "eval_steps: 24 / 371\n",
      "eval_steps: 25 / 371\n",
      "eval_steps: 26 / 371\n",
      "eval_steps: 27 / 371\n",
      "eval_steps: 28 / 371\n",
      "eval_steps: 29 / 371\n",
      "eval_steps: 30 / 371\n",
      "eval_steps: 31 / 371\n",
      "eval_steps: 32 / 371\n",
      "eval_steps: 33 / 371\n",
      "eval_steps: 34 / 371\n",
      "eval_steps: 35 / 371\n",
      "eval_steps: 36 / 371\n",
      "eval_steps: 37 / 371\n",
      "eval_steps: 38 / 371\n",
      "eval_steps: 39 / 371\n",
      "eval_steps: 40 / 371\n",
      "eval_steps: 41 / 371\n",
      "eval_steps: 42 / 371\n",
      "eval_steps: 43 / 371\n",
      "eval_steps: 44 / 371\n",
      "eval_steps: 45 / 371\n",
      "eval_steps: 46 / 371\n",
      "eval_steps: 47 / 371\n",
      "eval_steps: 48 / 371\n",
      "eval_steps: 49 / 371\n",
      "eval_steps: 50 / 371\n",
      "eval_steps: 51 / 371\n",
      "eval_steps: 52 / 371\n",
      "eval_steps: 53 / 371\n",
      "eval_steps: 54 / 371\n",
      "eval_steps: 55 / 371\n",
      "eval_steps: 56 / 371\n",
      "eval_steps: 57 / 371\n",
      "eval_steps: 58 / 371\n",
      "eval_steps: 59 / 371\n",
      "eval_steps: 60 / 371\n",
      "eval_steps: 61 / 371\n",
      "eval_steps: 62 / 371\n",
      "eval_steps: 63 / 371\n",
      "eval_steps: 64 / 371\n",
      "eval_steps: 65 / 371\n",
      "eval_steps: 66 / 371\n",
      "eval_steps: 67 / 371\n",
      "eval_steps: 68 / 371\n",
      "eval_steps: 69 / 371\n",
      "eval_steps: 70 / 371\n",
      "eval_steps: 71 / 371\n",
      "eval_steps: 72 / 371\n",
      "eval_steps: 73 / 371\n",
      "eval_steps: 74 / 371\n",
      "eval_steps: 75 / 371\n",
      "eval_steps: 76 / 371\n",
      "eval_steps: 77 / 371\n",
      "eval_steps: 78 / 371\n",
      "eval_steps: 79 / 371\n",
      "eval_steps: 80 / 371\n",
      "eval_steps: 81 / 371\n",
      "eval_steps: 82 / 371\n",
      "eval_steps: 83 / 371\n",
      "eval_steps: 84 / 371\n",
      "eval_steps: 85 / 371\n",
      "eval_steps: 86 / 371\n",
      "eval_steps: 87 / 371\n",
      "eval_steps: 88 / 371\n",
      "eval_steps: 89 / 371\n",
      "eval_steps: 90 / 371\n",
      "eval_steps: 91 / 371\n",
      "eval_steps: 92 / 371\n",
      "eval_steps: 93 / 371\n",
      "eval_steps: 94 / 371\n",
      "eval_steps: 95 / 371\n",
      "eval_steps: 96 / 371\n",
      "eval_steps: 97 / 371\n",
      "eval_steps: 98 / 371\n",
      "eval_steps: 99 / 371\n",
      "eval_steps: 100 / 371\n",
      "eval_steps: 101 / 371\n",
      "eval_steps: 102 / 371\n",
      "eval_steps: 103 / 371\n",
      "eval_steps: 104 / 371\n",
      "eval_steps: 105 / 371\n",
      "eval_steps: 106 / 371\n",
      "eval_steps: 107 / 371\n",
      "eval_steps: 108 / 371\n",
      "eval_steps: 109 / 371\n",
      "eval_steps: 110 / 371\n",
      "eval_steps: 111 / 371\n",
      "eval_steps: 112 / 371\n",
      "eval_steps: 113 / 371\n",
      "eval_steps: 114 / 371\n",
      "eval_steps: 115 / 371\n",
      "eval_steps: 116 / 371\n",
      "eval_steps: 117 / 371\n",
      "eval_steps: 118 / 371\n",
      "eval_steps: 119 / 371\n",
      "eval_steps: 120 / 371\n",
      "eval_steps: 121 / 371\n",
      "eval_steps: 122 / 371\n",
      "eval_steps: 123 / 371\n",
      "eval_steps: 124 / 371\n",
      "eval_steps: 125 / 371\n",
      "eval_steps: 126 / 371\n",
      "eval_steps: 127 / 371\n",
      "eval_steps: 128 / 371\n",
      "eval_steps: 129 / 371\n",
      "eval_steps: 130 / 371\n",
      "eval_steps: 131 / 371\n",
      "eval_steps: 132 / 371\n",
      "eval_steps: 133 / 371\n",
      "eval_steps: 134 / 371\n",
      "eval_steps: 135 / 371\n",
      "eval_steps: 136 / 371\n",
      "eval_steps: 137 / 371\n",
      "eval_steps: 138 / 371\n",
      "eval_steps: 139 / 371\n",
      "eval_steps: 140 / 371\n",
      "eval_steps: 141 / 371\n",
      "eval_steps: 142 / 371\n",
      "eval_steps: 143 / 371\n",
      "eval_steps: 144 / 371\n",
      "eval_steps: 145 / 371\n",
      "eval_steps: 146 / 371\n",
      "eval_steps: 147 / 371\n",
      "eval_steps: 148 / 371\n",
      "eval_steps: 149 / 371\n",
      "eval_steps: 150 / 371\n",
      "eval_steps: 151 / 371\n",
      "eval_steps: 152 / 371\n",
      "eval_steps: 153 / 371\n",
      "eval_steps: 154 / 371\n",
      "eval_steps: 155 / 371\n",
      "eval_steps: 156 / 371\n",
      "eval_steps: 157 / 371\n",
      "eval_steps: 158 / 371\n",
      "eval_steps: 159 / 371\n",
      "eval_steps: 160 / 371\n",
      "eval_steps: 161 / 371\n",
      "eval_steps: 162 / 371\n",
      "eval_steps: 163 / 371\n",
      "eval_steps: 164 / 371\n",
      "eval_steps: 165 / 371\n",
      "eval_steps: 166 / 371\n",
      "eval_steps: 167 / 371\n",
      "eval_steps: 168 / 371\n",
      "eval_steps: 169 / 371\n",
      "eval_steps: 170 / 371\n",
      "eval_steps: 171 / 371\n",
      "eval_steps: 172 / 371\n",
      "eval_steps: 173 / 371\n",
      "eval_steps: 174 / 371\n",
      "eval_steps: 175 / 371\n",
      "eval_steps: 176 / 371\n",
      "eval_steps: 177 / 371\n",
      "eval_steps: 178 / 371\n",
      "eval_steps: 179 / 371\n",
      "eval_steps: 180 / 371\n",
      "eval_steps: 181 / 371\n",
      "eval_steps: 182 / 371\n",
      "eval_steps: 183 / 371\n",
      "eval_steps: 184 / 371\n",
      "eval_steps: 185 / 371\n",
      "eval_steps: 186 / 371\n",
      "eval_steps: 187 / 371\n",
      "eval_steps: 188 / 371\n",
      "eval_steps: 189 / 371\n",
      "eval_steps: 190 / 371\n",
      "eval_steps: 191 / 371\n",
      "eval_steps: 192 / 371\n",
      "eval_steps: 193 / 371\n",
      "eval_steps: 194 / 371\n",
      "eval_steps: 195 / 371\n",
      "eval_steps: 196 / 371\n",
      "eval_steps: 197 / 371\n",
      "eval_steps: 198 / 371\n",
      "eval_steps: 199 / 371\n",
      "eval_steps: 200 / 371\n",
      "eval_steps: 201 / 371\n",
      "eval_steps: 202 / 371\n",
      "eval_steps: 203 / 371\n",
      "eval_steps: 204 / 371\n",
      "eval_steps: 205 / 371\n",
      "eval_steps: 206 / 371\n",
      "eval_steps: 207 / 371\n",
      "eval_steps: 208 / 371\n",
      "eval_steps: 209 / 371\n",
      "eval_steps: 210 / 371\n",
      "eval_steps: 211 / 371\n",
      "eval_steps: 212 / 371\n",
      "eval_steps: 213 / 371\n",
      "eval_steps: 214 / 371\n",
      "eval_steps: 215 / 371\n",
      "eval_steps: 216 / 371\n",
      "eval_steps: 217 / 371\n",
      "eval_steps: 218 / 371\n",
      "eval_steps: 219 / 371\n",
      "eval_steps: 220 / 371\n",
      "eval_steps: 221 / 371\n",
      "eval_steps: 222 / 371\n",
      "eval_steps: 223 / 371\n",
      "eval_steps: 224 / 371\n",
      "eval_steps: 225 / 371\n",
      "eval_steps: 226 / 371\n",
      "eval_steps: 227 / 371\n",
      "eval_steps: 228 / 371\n",
      "eval_steps: 229 / 371\n",
      "eval_steps: 230 / 371\n",
      "eval_steps: 231 / 371\n",
      "eval_steps: 232 / 371\n",
      "eval_steps: 233 / 371\n",
      "eval_steps: 234 / 371\n",
      "eval_steps: 235 / 371\n",
      "eval_steps: 236 / 371\n",
      "eval_steps: 237 / 371\n",
      "eval_steps: 238 / 371\n",
      "eval_steps: 239 / 371\n",
      "eval_steps: 240 / 371\n",
      "eval_steps: 241 / 371\n",
      "eval_steps: 242 / 371\n",
      "eval_steps: 243 / 371\n",
      "eval_steps: 244 / 371\n",
      "eval_steps: 245 / 371\n",
      "eval_steps: 246 / 371\n",
      "eval_steps: 247 / 371\n",
      "eval_steps: 248 / 371\n",
      "eval_steps: 249 / 371\n",
      "eval_steps: 250 / 371\n",
      "eval_steps: 251 / 371\n",
      "eval_steps: 252 / 371\n",
      "eval_steps: 253 / 371\n",
      "eval_steps: 254 / 371\n",
      "eval_steps: 255 / 371\n",
      "eval_steps: 256 / 371\n",
      "eval_steps: 257 / 371\n",
      "eval_steps: 258 / 371\n",
      "eval_steps: 259 / 371\n",
      "eval_steps: 260 / 371\n",
      "eval_steps: 261 / 371\n",
      "eval_steps: 262 / 371\n",
      "eval_steps: 263 / 371\n",
      "eval_steps: 264 / 371\n",
      "eval_steps: 265 / 371\n",
      "eval_steps: 266 / 371\n",
      "eval_steps: 267 / 371\n",
      "eval_steps: 268 / 371\n",
      "eval_steps: 269 / 371\n",
      "eval_steps: 270 / 371\n",
      "eval_steps: 271 / 371\n",
      "eval_steps: 272 / 371\n",
      "eval_steps: 273 / 371\n",
      "eval_steps: 274 / 371\n",
      "eval_steps: 275 / 371\n",
      "eval_steps: 276 / 371\n",
      "eval_steps: 277 / 371\n",
      "eval_steps: 278 / 371\n",
      "eval_steps: 279 / 371\n",
      "eval_steps: 280 / 371\n",
      "eval_steps: 281 / 371\n",
      "eval_steps: 282 / 371\n",
      "eval_steps: 283 / 371\n",
      "eval_steps: 284 / 371\n",
      "eval_steps: 285 / 371\n",
      "eval_steps: 286 / 371\n",
      "eval_steps: 287 / 371\n",
      "eval_steps: 288 / 371\n",
      "eval_steps: 289 / 371\n",
      "eval_steps: 290 / 371\n",
      "eval_steps: 291 / 371\n",
      "eval_steps: 292 / 371\n",
      "eval_steps: 293 / 371\n",
      "eval_steps: 294 / 371\n",
      "eval_steps: 295 / 371\n",
      "eval_steps: 296 / 371\n",
      "eval_steps: 297 / 371\n",
      "eval_steps: 298 / 371\n",
      "eval_steps: 299 / 371\n",
      "eval_steps: 300 / 371\n",
      "eval_steps: 301 / 371\n",
      "eval_steps: 302 / 371\n",
      "eval_steps: 303 / 371\n",
      "eval_steps: 304 / 371\n",
      "eval_steps: 305 / 371\n",
      "eval_steps: 306 / 371\n",
      "eval_steps: 307 / 371\n",
      "eval_steps: 308 / 371\n",
      "eval_steps: 309 / 371\n",
      "eval_steps: 310 / 371\n",
      "eval_steps: 311 / 371\n",
      "eval_steps: 312 / 371\n",
      "eval_steps: 313 / 371\n",
      "eval_steps: 314 / 371\n",
      "eval_steps: 315 / 371\n",
      "eval_steps: 316 / 371\n",
      "eval_steps: 317 / 371\n",
      "eval_steps: 318 / 371\n",
      "eval_steps: 319 / 371\n",
      "eval_steps: 320 / 371\n",
      "eval_steps: 321 / 371\n",
      "eval_steps: 322 / 371\n",
      "eval_steps: 323 / 371\n",
      "eval_steps: 324 / 371\n",
      "eval_steps: 325 / 371\n",
      "eval_steps: 326 / 371\n",
      "eval_steps: 327 / 371\n",
      "eval_steps: 328 / 371\n",
      "eval_steps: 329 / 371\n",
      "eval_steps: 330 / 371\n",
      "eval_steps: 331 / 371\n",
      "eval_steps: 332 / 371\n",
      "eval_steps: 333 / 371\n",
      "eval_steps: 334 / 371\n",
      "eval_steps: 335 / 371\n",
      "eval_steps: 336 / 371\n",
      "eval_steps: 337 / 371\n",
      "eval_steps: 338 / 371\n",
      "eval_steps: 339 / 371\n",
      "eval_steps: 340 / 371\n",
      "eval_steps: 341 / 371\n",
      "eval_steps: 342 / 371\n",
      "eval_steps: 343 / 371\n",
      "eval_steps: 344 / 371\n",
      "eval_steps: 345 / 371\n",
      "eval_steps: 346 / 371\n",
      "eval_steps: 347 / 371\n",
      "eval_steps: 348 / 371\n",
      "eval_steps: 349 / 371\n",
      "eval_steps: 350 / 371\n",
      "eval_steps: 351 / 371\n",
      "eval_steps: 352 / 371\n",
      "eval_steps: 353 / 371\n",
      "eval_steps: 354 / 371\n",
      "eval_steps: 355 / 371\n",
      "eval_steps: 356 / 371\n",
      "eval_steps: 357 / 371\n",
      "eval_steps: 358 / 371\n",
      "eval_steps: 359 / 371\n",
      "eval_steps: 360 / 371\n",
      "eval_steps: 361 / 371\n",
      "eval_steps: 362 / 371\n",
      "eval_steps: 363 / 371\n",
      "eval_steps: 364 / 371\n",
      "eval_steps: 365 / 371\n",
      "eval_steps: 366 / 371\n",
      "eval_steps: 367 / 371\n",
      "eval_steps: 368 / 371\n",
      "eval_steps: 369 / 371\n",
      "eval_steps: 370 / 371\n",
      "eval_steps: 371 / 371\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "final_test_performance = evaluation(test_dataloader, device, model)\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "with open(\"./nli_pred.txt\", 'w+') as file:\n",
    "    json.dump(final_test_performance, file, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11848\n"
     ]
    }
   ],
   "source": [
    "def unflatten(list, pattern):\n",
    "    cnt = 0\n",
    "    new_list = []\n",
    "    for i in range(1000):\n",
    "        l = 2 * len(pattern.get(i, []))\n",
    "        new_list.append(list[cnt:cnt + l])\n",
    "        cnt += l\n",
    "    print(cnt)\n",
    "    assert cnt == len(list)\n",
    "    return new_list\n",
    "\n",
    "nli_grouped_by_image_id = (unflatten(final_test_performance, context_files_grouped_by_image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "848ec3303aa6c64d107256817a16d6a039fa8cfd0fa250d143bf87759298d876"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
